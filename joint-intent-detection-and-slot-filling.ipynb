{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e39565f-01fe-4d64-ad1a-83d69e597052",
   "metadata": {},
   "source": [
    "# Joint Intent detection and slot filling\n",
    "Dieses Jupyter notebook wurde als semesterabschließende Arbeit für das Modul Natural Language Processing an der [Fachhochschule Südwestfalen](https://www.fh-swf.de/en/international_3/index.php) erstellt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e89dc9-708f-4c4f-8371-36f810242e7d",
   "metadata": {},
   "source": [
    "## Einleitung\n",
    "Das Joint intent detection and slot filling (IDSF) ist eine Aufgabe aus dem Teilbereich des Natural Language Understandings (NLU) des Natural Language Processings (NLP), die uns in heutzutage fast täglich Alltag begegnet. Sei es um einen Timer auf dem Handy zu starten, bestimmte Musik abzuspielen oder das Licht einzuschalten. Der Ablauf ist dabei häufig der selbe: \"Siri stelle einen Timer für 4 Minuten\", \"Alexa spiele meine Schlager Playlist\" oder \"Google erstelle einen Arzttermin für heute 16:00 Uhr\". Meist beginnen die Kommandos mit dem Namen des Sprachassistenten, um diesen zu aktivieren, gefolgt vom Kommando für die gewünschte Aktion. Das IDSF beschäftigt sich dabei mit der Aufgabe, die gewünschte Aktion (Intent), also stelle einen Timer, Spiele Musik, erstelle einen Termin im Kalender und die dazugehörigen notwendigen Parameter, wie z.B. vier Minuten, Schlager Playlist oder Arzt heute 16:00 Uhr (Slots) zu erkennen.\n",
    "Da der Gebrauch dieser Sprachassistenten in Zukunft wahrscheinlich noch stärker zu nehmen wird, wollen wir uns deren funktionsweise in diesem Notebook näher anschauen. Dafür wird zuerst die Entwicklungshistorie vom IDSF betrachtet und anschließend wird ein eigenes Modell für die Erkennung erstellt und anhand eines selbst vorbereiteten Korpus trainiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d088a2-b7f1-41f3-bd3b-1858acb800e7",
   "metadata": {},
   "source": [
    "## Joint Intent Detection and Slot filling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8bb627-85be-4f27-b800-9860a15cb12f",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f3c76-2bf2-49ff-9c87-6a1841c2c9ef",
   "metadata": {},
   "source": [
    "## Datenbeschaffung\n",
    "\n",
    "Als Datensatz für das nachfolgende Beispiel verwenden wir den Snips-Datensatz. Dieser Datensatz wurde vom, mittlerweil zu Sonos gehörenden [1], [Snips Team](https://snips.ai/) zusammengestellt, um ihr eigenes Modell mit anderen Wettbewerbern wie zum Beispiel Amazons Alexa zu verglichen. Die Ergebnisse und die Datensätze der drei Vergleiche wurden in einem [GitHub Repository](https://github.com/sonos/nlu-benchmark/tree/master) veröffentlicht und in dem Paper \"Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces\" [2] erläutert. Das Repository enthält die Daten für drei Evaluationen aus den Jahren 2016 bis 2018. Wir werden in diesem Notebook die Daten der 2017 durchgeführten Evaluation verwenden, da diese Sätze für sieben unterschiedliche und allgemeine Aufgaben enthält.\n",
    "\n",
    "Die Daten sind im dem Repository in einzelnen JSON-Dateien enthalten. Dabei gibt es pro Aufgabe zwei Dateien, eine für das Training und eine für die Validierung. Der Einfachheit halber wurden die Dateien in dem data Verzeichnis, dass diesem Notebook beiliegt, abgelegt.\n",
    "\n",
    "Nachfolgend ist ein Auszug aus der `train_AddToPlaylist_full.json`-Datei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b04077bd-4c1c-475b-bd64-997f7afd2ef0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"AddToPlaylist\": [\n",
      "    {\n",
      "      \"data\": [\n",
      "        {\n",
      "          \"text\": \"Add another \"\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"song\",\n",
      "          \"entity\": \"music_item\"\n",
      "        },\n",
      "        {\n",
      "          \"text\": \" to the \"\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Cita Romántica\",\n",
      "          \"entity\": \"playlist\"\n",
      "        },\n",
      "        {\n",
      "          \"text\": \" playlist. \"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"data\": [\n",
      "        {\n",
      "          \"text\": \"add \"\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"clem burke\",\n",
      "          \"entity\": \"artist\"\n",
      "        },\n",
      "        {\n",
      "          \"text\": \" in \"\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"my\",\n",
      "          \"entity\": \"playlist_owner\"\n",
      "        },\n",
      "        {\n",
      "          \"text\": \" playlist \"\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Pre-Party R&B Jams\",\n",
      "          \"entity\": \"playlist\"\n",
      "        }\n",
      "      ]\n",
      "    },\n"
     ]
    }
   ],
   "source": [
    "!head -n 48 data/train_AddToPlaylist_full.json # Zeige die ersten 23 Zeilen der angegebenen Datei an."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7977d9c-5cc6-4725-9386-46716911c4f5",
   "metadata": {},
   "source": [
    "Die Datei besteht an oberster Stelle aus dem Namen der gewünschten Aktion gefolgt von einer Liste an Objekten mit einem `Data` Attribut. Dieses enthält wiederum eine Liste von Objekten mit `Text` Attributen die den Satz in Teilen enthält. Dabei wird der Satz durch den Text eines definierten `Entities` geteilt. So enthält das erste Beispiel den Text bis zum ersten `entity` das als `music_item` klassifiziert wurde und wieder den gesamten Text bis zum nächsten entity, dem Namen einer Playlist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c5966d-61dc-45af-8107-2fbf9f55b2de",
   "metadata": {},
   "source": [
    "Als nächstes werden die Daten in ein verwendbares Format transformiert. Ein in der Natural language processing gängiges Format ist das IOB Format. IOB steht für Inside-Outside-Beginning. Dieses Format ermöglicht die Kennzeichnung der einzelnen Entitäten in einem Satz. Es wird unteranderem von den weit verbreiteten Python Bibliotheken `NLTK` und `spaCy` unterstützt [3, 4]. Das Format wurde 1995 von Lance A. Ramshaw und Mitchell P. Marcus erfunden.\n",
    "\n",
    "Dieses Beispiel zeigt das Format einer Zeile, welches nachfolgend aus den JSON-Dateien erzeugt wird. Die IOB-Kodierung ist hinter der Intent-Kategorie `AddToPlaylist` zu sehen.\n",
    "\n",
    "    BOS add clem burke in my playlist Pre-Party R&B Jams EOS AddToPlaylist o o b-mucic_item i-music_item o i-playlist_owner o b-playlist i-playlist i-playlist\n",
    "    \n",
    "Am Beginn der Zeile steht der vollständige Satz abgetrennt durch ein BOS (begin of sentence) am Anfang des Satzes und ein EOS (end of sentence) am Ende des Satzes. Dahinter wird die Aktion (Intent) definiert. Nun folgt das eigentliche IOB-Format. Dabei wird für jeden Token entweder der Buchstabe 'o', dieser steht für keine Bedeutung, der Buchstabe 'b', für den Beginn einer Entität die aus mehreren Token besteht, oder 'i', als Entität. Das 'i' steht dabei entweder nach einem 'b' wodurch eine Entität gekennzeichent wird, die aus mehreren Token besteht oder alleine für eine Entität die aus nur einem Token besteht.  Das 'b' und 'i' werden dabei jeweils gefolgt vom einem trennenden Bindestrich und der Entitätskategorie verwender. So ist der Name 'Clem Burke' unterteilt in ein `b-music_item` für Clem und `i-Music_item` für Burke. Dadurch wird definiert, dass die beiden Teile zusammen gehören.\n",
    "\n",
    "Das IOB2 Format ist eine Erweiterung des originalen IOB Formats. Es definiert das auch eine Entität die nur aus einem Token besteht mit einem 'b' kodiert wird und nicht wie im IOB Format mit einem 'i'. Dadurch ergibt sich das folgende Format:\n",
    "\n",
    "    BOS add clem burke in my playlist Pre-Party R&B Jams EOS AddToPlaylist o o b-mucic_item i-music_item o b-playlist_owner o b-playlist i-playlist i-playlist\n",
    "    \n",
    "\n",
    "Mit dem folgenden Python Code wird der Inhalt der im data-Verzeichnis liegenden Dateien in das vorgestellte Format transformiert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f23b37ed-4ed4-4f10-b47f-d9856cac14ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from shutil import rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "049daa05-aa7a-4076-b36a-f4deb1ee1e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pfad data/formatted ist kein Verzeichnis oder existiert nicht\n",
      "Das Pfad data existiert nicht oder ist kein Verzeichnis.\n",
      "Try converting file at path data/validate_PlayMusic.json\n",
      "Finished converting file at path data/validate_PlayMusic.json. Writing to file...\n",
      "Try converting file at path data/train_SearchCreativeWork_full.json\n",
      "Finished converting file at path data/train_SearchCreativeWork_full.json. Writing to file...\n",
      "Try converting file at path data/train_AddToPlaylist_full.json\n",
      "Finished converting file at path data/train_AddToPlaylist_full.json. Writing to file...\n",
      "Try converting file at path data/train_RateBook_full.json\n",
      "Finished converting file at path data/train_RateBook_full.json. Writing to file...\n",
      "Try converting file at path data/train_SearchScreeningEvent_full.json\n",
      "Finished converting file at path data/train_SearchScreeningEvent_full.json. Writing to file...\n",
      "Try converting file at path data/validate_GetWeather.json\n",
      "Finished converting file at path data/validate_GetWeather.json. Writing to file...\n",
      "Try converting file at path data/validate_SearchCreativeWork.json\n",
      "Finished converting file at path data/validate_SearchCreativeWork.json. Writing to file...\n",
      "Try converting file at path data/train_GetWeather_full.json\n",
      "Finished converting file at path data/train_GetWeather_full.json. Writing to file...\n",
      "Try converting file at path data/train_PlayMusic_full.json\n",
      "Finished converting file at path data/train_PlayMusic_full.json. Writing to file...\n",
      "Try converting file at path data/validate_RateBook.json\n",
      "Finished converting file at path data/validate_RateBook.json. Writing to file...\n",
      "Try converting file at path data/validate_AddToPlaylist.json\n",
      "Finished converting file at path data/validate_AddToPlaylist.json. Writing to file...\n",
      "Try converting file at path data/validate_BookRestaurant.json\n",
      "Finished converting file at path data/validate_BookRestaurant.json. Writing to file...\n",
      "Try converting file at path data/train_BookRestaurant_full.json\n",
      "Finished converting file at path data/train_BookRestaurant_full.json. Writing to file...\n",
      "Try converting file at path data/validate_SearchScreeningEvent.json\n",
      "Finished converting file at path data/validate_SearchScreeningEvent.json. Writing to file...\n",
      "Finished converting all files!\n"
     ]
    }
   ],
   "source": [
    "def clean_formatted(formatted_directory_path):\n",
    "    if not os.path.exists(formatted_directory_path) or not os.path.isdir(formatted_directory_path):\n",
    "        print(f'Pfad {formatted_directory_path} ist kein Verzeichnis oder existiert nicht')\n",
    "        return\n",
    "\n",
    "    rmtree(formatted_directory_path)\n",
    "    print('Alte Corpus-Dateien gelöscht')\n",
    "\n",
    "def convert_file(json_file_path):\n",
    "    print(f'Try converting file at path {json_file_path}')\n",
    "    if not os.path.isfile(json_file_path):\n",
    "        print(f'File {file_path} does not exists', json_file_path)\n",
    "        return \n",
    "    formatted_lines = []\n",
    "    intent_category = None\n",
    "    with open(json_file_path, 'r', encoding='latin-1') as json_file:\n",
    "        json_content = json.load(json_file)\n",
    "        intent_category = next(iter(json_content))\n",
    "        for sentence_block in json_content[intent_category]:\n",
    "            sentence = \"\"\n",
    "            slots = []\n",
    "            for sentence_data_block in sentence_block['data']:\n",
    "                sentence_part = sentence_data_block['text']\n",
    "                sentence_part = re.sub('\\n', '', sentence_part)\n",
    "                if sentence_part != '':\n",
    "                    sentence += sentence_part\n",
    "                sentence_part_len = len(sentence_part.split())\n",
    "                if 'entity' in sentence_data_block:\n",
    "                    entity_type = sentence_data_block['entity']\n",
    "                    if sentence_part_len > 1:\n",
    "                        firstSlot = True\n",
    "                        for i in range(sentence_part_len):\n",
    "                            if firstSlot:\n",
    "                                slots.append('b-' + entity_type)\n",
    "                                firstSlot = False\n",
    "                            else:\n",
    "                                slots.append('i-' + entity_type)\n",
    "                    else:\n",
    "                        slots.append('b-' + entity_type)\n",
    "                else:\n",
    "                    for i in range(sentence_part_len):\n",
    "                        slots.append('o')\n",
    "            formatted_lines.append(construct_row(sentence, intent_category, slots))\n",
    "    print(f'Finished converting file at path {json_file_path}. Writing to file...')\n",
    "    write_to_file(intent_category, formatted_lines)\n",
    "    \n",
    "\n",
    "def construct_row(sentence, intent, slots):\n",
    "    row = 'BOS '\n",
    "    row += sentence\n",
    "    row += ' EOS '\n",
    "    row += intent\n",
    "    row += ' '\n",
    "    row += ' '.join(slots)\n",
    "    row += '\\n'\n",
    "    return row\n",
    "\n",
    "\n",
    "def write_to_file(intent, lines):\n",
    "    if intent is None or intent == '':\n",
    "        print('No intent')\n",
    "        return\n",
    "        \n",
    "    base_output_directory = 'data/formatted/'\n",
    "    output_file_path = base_output_directory + intent + '.txt'\n",
    "\n",
    "    if not os.path.exists(base_output_directory): \n",
    "        os.makedirs(base_output_directory)\n",
    "    \n",
    "    with open(output_file_path, 'a') as output_file:\n",
    "        output_file.writelines(lines)\n",
    "\n",
    "\n",
    "def iterate_over_json_files_in_directory(directory_path):\n",
    "    if not os.path.exists(directory_path) or directory_path is not os.path.isdir(directory_path):\n",
    "        print(f\"Das Pfad {directory_path} existiert nicht oder ist kein Verzeichnis.\")\n",
    "        \n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".json\"):  # Nur JSON-Dateien berücksichtigen\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            convert_file(file_path)\n",
    "    print('Finished converting all files!')\n",
    "    \n",
    "clean_formatted('data/formatted')\n",
    "iterate_over_json_files_in_directory('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c2dd92-a1b1-404d-b1af-e13fa5ebbfa4",
   "metadata": {},
   "source": [
    "Als nächstes wird geprüft, ob auch alle Einträge in der Textdatei enthalten sind. Dafür werden die Einträge in der train- und validate.json mit der Anzahl der Zeilen in der Textdatei verglichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99108436-e37e-4954-be8d-66a2e8104be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2056 data/formatted/RateBook.txt\n"
     ]
    }
   ],
   "source": [
    "!wc -l data/formatted/RateBook.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "579d5d3c-fc2a-490c-98fe-c98bf612674c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;39m1956\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!jq '.RateBook | length' data/train_RateBook_full.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "431915fc-2450-4617-aad4-37ecd6e94991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;39m100\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!jq '.RateBook | length' data/validate_RateBook.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8490f728-7789-4273-902a-8f9f11235122",
   "metadata": {},
   "source": [
    "Man sieht, dass die Anzahl der `data`-Blöcke aus den JSON-Dateien der Anzahl der Zeilen in der erzeugten Textdatei entspricht. Die Konvertierung war also erfolgreich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d32f47ef-983c-4ba5-a359-a808e2cf2a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOS rate The Lotus and the Storm zero of 6 EOS RateBook o b-object_name i-object_name i-object_name i-object_name i-object_name b-rating_value o b-best_rating\n",
      "BOS Rate The Fall-Down Artist 5 stars. EOS RateBook o b-object_name i-object_name i-object_name b-rating_value b-rating_unit o\n",
      "BOS Rate the current novel one points EOS RateBook o o b-object_select b-object_type b-rating_value b-rating_unit\n",
      "BOS rate The Ape-Man Within 4 EOS RateBook o b-object_name i-object_name i-object_name b-rating_value\n",
      "BOS I give The Penalty three stars EOS RateBook o o b-object_name i-object_name b-rating_value b-rating_unit\n",
      "BOS rate this novel a 4 EOS RateBook o b-object_select b-object_type o b-rating_value\n",
      "BOS give 5 out of 6 points to Absolutely, Positively Not series EOS RateBook o b-rating_value o o b-best_rating b-rating_unit o b-object_name i-object_name i-object_name b-object_part_of_series_type\n",
      "BOS I give Emile, or On Education five points. EOS RateBook o o b-object_name i-object_name i-object_name i-object_name b-rating_value b-rating_unit o\n",
      "BOS rate Licence Renewed a 4 EOS RateBook o b-object_name i-object_name o b-rating_value\n",
      "BOS Give this essay a 2 out of 6. EOS RateBook o b-object_select b-object_type o b-rating_value o o b-best_rating o\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 data/formatted/RateBook.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e9ff63-9acc-462e-b20b-c39fcb78caf4",
   "metadata": {},
   "source": [
    "Quellen\n",
    "\n",
    "* 1: https://investors.sonos.com/news-and-events/investor-news/latest-news/2019/Sonos-Announces-Acquisition-of-Snips/default.aspx, [Online, 07.03.2025]\n",
    "* 2: Coucke A. et al., \"Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces.\" 2018, [Online: https://arxiv.org/abs/1805.10190, 07.03.2025]\n",
    "* 3: NLTK Team, tree2conlltags, [Online: https://www.nltk.org/_modules/nltk/chunk/util.html#tree2conlltags, 13.03.2025]\n",
    "* 4: Explosion, spaCy convert, [Online: https://spacy.io/api/cli#converters, 13.03.2025]\n",
    "* 5: Ramshaw und Marcus, \"Text Chunking using Transformation-Based Learning\" 1995, [Online: https://arxiv.org/abs/cmp-lg/9505040, 14.03.2025]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511baabd-4337-4292-9483-482fd44392e8",
   "metadata": {},
   "source": [
    "## Erstellen eines Corpus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
